{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGSMPHpGZOE1"
      },
      "source": [
        "<h1 align=center style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
        "<font face=\"vazir\" color=\"#0099cc\">\n",
        "فعالیت‌بدنی‌بندی</font>\n",
        "</h1>\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl;text-align: justify;line-height:200%;font-family:vazir;font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "مجموعه‌داده‌های <b>تشخیص فعالیت انسانی (HAR)</b> مجموعه‌ای از داده‌های حسگر هستند که هدف آنها دسته‌بندی و شناسایی فعالیت‌های مختلف انسانی بر اساس الگوهای موجود در خوانش‌های حسگر است. در تحقیقات یادگیری ماشین و داده‌کاوی از این مجموعه‌داده‌ها برای توسعه‌ی الگوریتم‌ها و مدل‌های سیستم‌های تشخیص فعالیت استفاده می‌شوند. ویژگی‌های مجموعه‌داده‌های HAR معمولاً برگرفته از داده‌های حسگرهای مختلف مانند شتاب‌سنج، ژیروسکوپ و مغناطیس‌سنج است. این سنسورها معمولاً در گوشی‌های هوشمند، ساعت‌های هوشمند و دستگاه‌های پوشیدنی یافت می‌شوند. حسگرها داده‌های مربوط به حرکت و جهت‌گیری دستگاه و همچنین محیط اطراف را ثبت می‌کنند. در صورت علاقه، می‌توانید نمونه‌ای از ثبت این داده‌ها را در <a href=\"https://www.youtube.com/watch?v=XOEN9W05_4A\">این ویدیو</a> مشاهده کنید. این اندازه‌گیری‌ها در فواصل زمانی منظم گرفته می‌شوند و به‌عنوان داده‌های سری زمانی نشان داده می‌شوند. هدف مجموعه‌داده‌های HAR شناسایی و دسته‌بندی دقیق فعالیت‌های انسانی خاص است. این فعالیت‌ها می توانند بسته به کاربرد یا زمینه‌ی مورد مطالعه متفاوت باشند. نمونه‌هایی از فعالیت‌های رایج شناخته‌شده عبارتند از راه رفتن، دویدن، ایستادن، نشستن، بالا رفتن از پله‌ها و فعالیت‌های مرتبط با ورزش یا تناسب اندام. هدف، ساخت مدل‌های پیش‌بینی‌کننده است تا بتوانند به‌طور خودکار این فعالیت‌ها را بر اساس الگوهای آشکار یا پنهان موجود در داده‌های حسگر تشخیص دهند و بین‌شان تمایز قائل شوند.\n",
        "<br>\n",
        "</font>\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58YV_pjJZOE7"
      },
      "source": [
        "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
        "<font face=\"vazir\">مجموعه‌داده</font>\n",
        "</h2>\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl;text-align: justify;line-height:200%;font-family:vazir;font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "در مجموعه‌داده‌ای که در اختیار شما قرار گرفته به‌ازای هر داده‌ای که ثبت شده نوع فعالیت آن در ستون <code>Activity_Name</code> نوشته شده است. انواع فعالیت موجود در این مجموعه‌داده عبارتند از:\n",
        "\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "<center>\n",
        "<p dir=rtl style=\"direction: rtl;text-align: justify;line-height:200%;font-family:vazir;font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "\n",
        "| مقدار | نوع فعالیت |\n",
        "| :---: | :---: |\n",
        "| Walking | راه رفتن |\n",
        "| Walking_Upstairs | بالا رفتن از پله‌ها |\n",
        "| Walking_Downstairs | پایین رفتن از پله‌ها |\n",
        "| Sitting | نشستن |\n",
        "| Standing | ایستادن |\n",
        "| Laying | خوابیدن |\n",
        "\n",
        "</font>\n",
        "</p>\n",
        "</center>\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl;text-align: justify;line-height:200%;font-family:vazir;font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "در ابتدا مجموعه‌داده‌های آموزش (<code>train</code>) و آزمون (<code>test</code>) از فایل‌های موجود در پوشه بخوانید. البته نیازی به ستون <code>subject</code> نیست. در صورت تمایل می‌توانید بخشی از مجموعه‌ی آموزشی را جدا کرده و برای اعتبارسنجی (<code>validation</code>) استفاده کنید.\n",
        "    </font>\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUWmskUZZOE9"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjuvdzzeZOFD"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2egpEXLFZOFE"
      },
      "outputs": [],
      "source": [
        "# Check the number of rows and columns\n",
        "print(train.shape)\n",
        "print(test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCEgI95wZOFI"
      },
      "outputs": [],
      "source": [
        "train.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sV1AEAv7ZOFI"
      },
      "outputs": [],
      "source": [
        "train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIKFmSwfZOFJ"
      },
      "outputs": [],
      "source": [
        "train.describe(include='all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwbed1MjZOFK"
      },
      "outputs": [],
      "source": [
        "test.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JUnHSfNZOFL"
      },
      "outputs": [],
      "source": [
        "test.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmbNG0DcZOFL"
      },
      "outputs": [],
      "source": [
        "test.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaMYK7HpZOFN"
      },
      "source": [
        "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
        "<font face=\"vazir\">تحلیل اکتشافی داده</font>\n",
        "</h2>\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl;text-align: justify;line-height:200%;font-family:vazir;font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "در ابتدا پیشنهاد می‌کنیم کمی به بررسی دقیق‌تر و آماری داده‌هایی که در دسترس‌تان است بپردازید و در صورت علاقه نمودارهایی را جهت بررسی توزیع‌های داده رسم کنید.\n",
        "<span style=\"color:orange\">(اختیاری)</span>\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FfIxQSZZOFN"
      },
      "outputs": [],
      "source": [
        "# EDA (Exploratory Data Analysis)\n",
        "\n",
        "# convert \"Activity_Name\" column to String data type\n",
        "train['Activity_Name'] = train['Activity_Name'].astype(str)\n",
        "train.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yh0DhltlZOFP"
      },
      "outputs": [],
      "source": [
        "train['Activity_Name'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZYw83QDZOFP"
      },
      "outputs": [],
      "source": [
        "train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeBtlPSzZOFQ"
      },
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "train.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lK2lfJFKZOFR"
      },
      "outputs": [],
      "source": [
        "train['Activity_Name'].value_counts() # train.value_counts('Activity_Name')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_uQqZFcZOFS"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check the distribution of activities\n",
        "train['Activity_Name'].value_counts().plot(kind='bar')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaCsWloNZOFS"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.countplot(x='Activity_Name', data=train)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eoMv1OKiZOFT"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Remove NaN and infinite values\n",
        "train['tBodyAcc-mean()-X'] = train['tBodyAcc-mean()-X'].replace([np.inf, -np.inf], np.nan)\n",
        "train['tBodyAcc-mean()-X'].dropna(inplace=True)\n",
        "\n",
        "# Remove NaN and infinite values\n",
        "train['tBodyAcc-mean()-Y'] = train['tBodyAcc-mean()-Y'].replace([np.inf, -np.inf], np.nan)\n",
        "train['tBodyAcc-mean()-Y'].dropna(inplace=True)\n",
        "\n",
        "# Remove NaN and infinite values\n",
        "train['tBodyAcc-mean()-Z'] = train['tBodyAcc-mean()-Z'].replace([np.inf, -np.inf], np.nan)\n",
        "train['tBodyAcc-mean()-Z'].dropna(inplace=True)\n",
        "\n",
        "# Plot the histogram\n",
        "# Try setting the range to be a finite value, e.g. [0, 10]\n",
        "fig, axes = plt.subplots(1, 3, figsize=(20, 8))\n",
        "axes[0].hist(train['tBodyAcc-mean()-X'].apply(np.log1p), range=[0, 10])\n",
        "axes[0].set_title('Logarithmic Energy Distribution of Accelerometer in X-Axis')\n",
        "axes[1].hist(train['tBodyAcc-mean()-Y'].apply(np.log1p), range=[0, 10])\n",
        "axes[1].set_title('Logarithmic Energy Distribution of Accelerometer in Y-Axis')\n",
        "axes[2].hist(train['tBodyAcc-mean()-Z'].apply(np.log1p), range=[0, 10])\n",
        "axes[2].set_title('Logarithmic Energy Distribution of Accelerometer in Z-Axis')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bMrky6wZOFU"
      },
      "source": [
        "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
        "<font face=\"vazir\">مهندسی ویژگی</font>\n",
        "</h2>\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl;text-align: justify;line-height:200%;font-family:vazir;font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "طبق بررسی‌هایی که از داده‌ها داشته‌اید یا جهت دست‌یابی به عملکرد بهتر در مدل‌های پیش‌بینی‌کننده‌ی خود ممکن است به مهندسی ویژگی‌‌ها (کدگذاری متغیر هدف،‌ حذف ویژگی‌ها، تغییر نوع ویژگی‌ها، ساخت ویژگی جدید، تغییر مقیاس و غیره) نیاز داشته باشید. در این‌صورت می‌توانید در این قسمت از هر روش یا ابزاری که مناسب می‌دانید به‌منظور مهندسی ویژگی‌ها استفاده کنید.\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_aG6kibZOFV"
      },
      "outputs": [],
      "source": [
        "## To-Do (Feature Engineering)\n",
        "## Combine the three acceleration mean features into a new feature\n",
        "#train['tBodyAcc-mean'] = np.sqrt(train['tBodyAcc-mean()-X']**2 + train['tBodyAcc-mean()-Y']**2 + train['tBodyAcc-mean()-Z']**2)\n",
        "#test['tBodyAcc-mean'] = np.sqrt(test['tBodyAcc-mean()-X']**2 + test['tBodyAcc-mean()-Y']**2 + test['tBodyAcc-mean()-Z']**2)\n",
        "\n",
        "#sns.boxplot(x='tBodyAcc-mean', data=train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IXs4-32ZOFV"
      },
      "outputs": [],
      "source": [
        "## Remove outliers\n",
        "#Q1 = train['tBodyAcc-mean'].quantile(0.25)\n",
        "#Q3 = train['tBodyAcc-mean'].quantile(0.75)\n",
        "#IQR = Q3 - Q1\n",
        "#train = train[train['tBodyAcc-mean'] <= Q3 + 1.5 * IQR]\n",
        "#train = train[train['tBodyAcc-mean'] >= Q1 - 1.5 * IQR]\n",
        "\n",
        "## Plot a boxplot for the feature 'tBodyAcc-mean'\n",
        "#plt.boxplot(train['tBodyAcc-mean'])\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNzcAEL8ZOFW"
      },
      "outputs": [],
      "source": [
        "#train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vdrY0lFZOFW"
      },
      "outputs": [],
      "source": [
        "def drop_outlier_zScore(data, threshold):\n",
        "    z_score = (data.iloc[:, :-1] - data.iloc[:, :-1].mean()) / data.iloc[:, :-1].std()\n",
        "    print((np.abs(z_score) < threshold).all(axis=1).sum())\n",
        "    filtered_data = data[(np.abs(z_score) < threshold).all(axis=1)]\n",
        "    return filtered_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q52BOp9lZOFX"
      },
      "outputs": [],
      "source": [
        "thresh = 8\n",
        "\n",
        "train_no_outlier = drop_outlier_zScore(data=train, threshold=thresh)\n",
        "\n",
        "train_no_outlier.shape\n",
        "\n",
        "train_no_outlier.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbfdyx_3ZOFX"
      },
      "outputs": [],
      "source": [
        "train_no_outlier.shape\n",
        "\n",
        "train = train_no_outlier.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3spAdCj_ZOFY"
      },
      "source": [
        "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
        "<font face=\"vazir\">مدل‌سازی</font>\n",
        "</h2>\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl;text-align: justify;line-height:200%;font-family:vazir;font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "اکنون می‌توانید با استفاده از الگوریتم‌های یادگیری ماشین، مدلی آموزش دهید که با گرفتن مقادیر ویژگی‌های دریافتی از سنسورها، نوع فعالیت در حال انجام را پیش‌بینی کند.\n",
        "در این قسمت از شما می‌خواهیم از الگوریتم <b>Support Vector Machine (SVM)</b> استفاده کنید و ترکیب‌های مختلفی از هایپرپارامترهای مهم این الگوریتم (<code>C</code>، <code>kernel</code> و <code>gamma</code>) را آزمایش کنید تا بهترین مدل را برای پیش‌بینی فعالیت‌های انسانی انتخاب کنید. در این قسمت می‌توانید از کتابخانه‌ی <code>sklearn</code> استفاده کنید و برای جست‌وجوی هایپرپارامترها می‌توانید از روشی همچون Grid Search استفاده کنید. منطقی است که برای پیدا کردن بهترین ترکیب هایپرپارامتر نیاز به مجموعه‌ی اعتبارسنجی یا استفاده از روش‌هایی مانند Cross Validation دارید.\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHkeu9pmZOFZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, KFold\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import make_scorer, f1_score\n",
        "\n",
        "# deleting categorical data\n",
        "X, y = train.drop(columns=['Subject', 'Activity_Name']), train['Activity_Name']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state= 42)\n",
        "\n",
        "# Label encoding\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# Create a label encoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Encode the target variable\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_test = le.transform(y_test)\n",
        "\n",
        "# Normalizer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Create a normalizer\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Scale the features\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "\n",
        "lda = LDA(n_components=5)\n",
        "X_train = lda.fit_transform(X_train, y_train)\n",
        "X_test = lda.transform(X_test)\n",
        "\n",
        "param_grid = {\n",
        "    \"kernel\": [\"rbf\", \"poly\"],\n",
        "    \"C\": [ 10, 100],\n",
        "    \"gamma\": [\"scale\",  0.01, 0.1, \"auto\"],\n",
        "    #\"max_iter\": [500, 1000, 2000]\n",
        "}\n",
        "\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "f1_weighted = make_scorer(f1_score, average=\"weighted\")\n",
        "\n",
        "# Train the model using Grid Search\n",
        "clf = RandomizedSearchCV(\n",
        "  SVC(),\n",
        "  param_grid,\n",
        "  scoring= f1_weighted,\n",
        "  refit=True,\n",
        "  cv=cv\n",
        ")\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4acS6PdZOFa"
      },
      "outputs": [],
      "source": [
        "r = pd.DataFrame(clf.cv_results_)\n",
        "r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6Q84k01ZOFa"
      },
      "outputs": [],
      "source": [
        "print(X.shape, y.shape)\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)\n",
        "print(clf.score(X_train,y_train))\n",
        "print(clf.score(X_test,y_test))\n",
        "print(clf.best_score_)\n",
        "# the best hyperparameters\n",
        "print(clf.best_params_)\n",
        "clf.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Best_Model = SVC(**clf.best_params_)\n",
        "Best_Model.get_params()"
      ],
      "metadata": {
        "id": "-fo3lU2wqxr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Best_Model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "XcQZzAZkrhso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2rBgZGyZOFb"
      },
      "source": [
        "<p dir=rtl style=\"direction: rtl;text-align: justify;line-height:200%;font-family:vazir;font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "با توجه به نتایجی که بر روی هر ترکیب هایپرپارامتر به دست آورده‌اید،‌ تاثیر هر یک از هایپرپارامترها را بر روی عملکرد مدل چه می‌دانید؟ دلایل و تحلیل خود را در سلول زیر بنویسید:\n",
        "<span style=\"color:red\">(ضروری)</span>\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ6H4x8LZOFb"
      },
      "source": [
        "<p dir=rtl style=\"direction: rtl;text-align: center;line-height:200%;font-family:vazir;font-size:medium;color:#0099cc\"><font face=\"vazir\" size=3><i>\n",
        "[تحلیل شما]\n",
        "</i></font></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhwpBpn0ZOFc"
      },
      "source": [
        "<p dir=rtl style=\"direction: rtl;text-align: justify;line-height:200%;font-family:vazir;font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "حال نتایج مدل نهایی انتخاب‌شده را هم بر روی مجموعه‌ی آموزشی و هم اعتبارسنجی گزارش کنید. برای ارزیابی از معیارهای Accuracy، Precision، Recall و F1-Score استفاده کنید. همچنین ماتریس درهم‌ریختگی (Confusion Matrix) را رسم نمایید.\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LlZcZ5iZOFd"
      },
      "outputs": [],
      "source": [
        "# To-Do (Evaluation)\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score #, mean_squared_error\n",
        "\n",
        "# Evaluate the model on the training set\n",
        "y_pred = Best_Model.predict((X_train))\n",
        "\n",
        "print('Accuracy:', accuracy_score(y_true=y_train, y_pred=y_pred))\n",
        "print('Precision:', precision_score(y_true=y_train, y_pred=y_pred, average='weighted'))\n",
        "print('Recall:', recall_score(y_true=y_train, y_pred=y_pred, average='weighted'))\n",
        "print('F1-Score:', f1_score(y_true=y_train, y_pred=y_pred, average='weighted'))\n",
        "#print('MSE:', mean_squared_error(y_true=y_train, y_pred=y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWxXKxbrZOFd"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "confusion_matrix = confusion_matrix(y_true=y_train, y_pred=y_pred)\n",
        "print(confusion_matrix)\n",
        "\n",
        "# Plot confusion matrix\n",
        "titles_options = [\n",
        "    (\"Confusion matrix\")\n",
        "]\n",
        "for title in titles_options:\n",
        "    disp = ConfusionMatrixDisplay.from_estimator(\n",
        "        clf,\n",
        "        X_test,\n",
        "        y_test,\n",
        "        cmap=plt.cm.Blues,\n",
        "    )\n",
        "    disp.ax_.set_title(title)\n",
        "\n",
        "for title in titles_options:\n",
        "    disp = ConfusionMatrixDisplay.from_estimator(\n",
        "        clf,\n",
        "        X_train,\n",
        "        y_train,\n",
        "        cmap=plt.cm.Blues,\n",
        "    )\n",
        "    disp.ax_.set_title(title)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "#    ConfusionMatrixDisplay.from_predictions(\n",
        "#        y_test, y_pred\n",
        "#    )\n",
        "#\n",
        "#    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_JWeHuuZOFe"
      },
      "source": [
        "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
        "<font face=\"vazir\">پیش‌بینی برای مجموعه‌ی آزمون</font>\n",
        "</h2>\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl;text-align: justify;line-height:200%;font-family:vazir;font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "اکنون از مدلی که آموزش داده‌اید برای پیش‌بینی نمونه‌های مجموعه‌ی آزمون استفاده کرده تا متوجه شوید که مدل شما تا چه میزان برای نمونه‌های جدید و مشاهده‌نشده موفق عمل می‌کند. نیاز است پیش‌بینی‌های مدل خود را در یک دیتافریم با نام <code>submission</code> که شامل یک ستون به نام <code>Activity_Name</code> است ذخیره کنید. ردیف اول از این دیتافریم، پیش‌بینی مدل شما برای نمونه‌ی نخست و ردیف آخر از آن،‌ پیش‌بینی مدل شما برای نمونه‌ی آخر مجموعه‌ی آزمون است. توجه داشته باشید که مقادیر این ستون باید از جنس دسته‌ای و مشابه با مقادیر آن در مجموعه‌ی آموزشی باشد. یک نمونه‌ی فرضی از دیتافریم شما در جدول زیر نشان داده شده است:\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "<center>\n",
        "<p dir=rtl style=\"direction: rtl;text-align: justify;line-height:200%;font-family:vazir;font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "\n",
        "| <code>Activity_Name</code> |\n",
        "| :---: |\n",
        "| Walking |\n",
        "| Sitting |\n",
        "| Sitting |\n",
        "| Walking_Upstairs |\n",
        "| ... |\n",
        "\n",
        "</font>\n",
        "</p>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1B_OmuMZOFf"
      },
      "outputs": [],
      "source": [
        "# TO-DO (Predictions)\n",
        "\n",
        "test = scaler.transform(test)\n",
        "test = lda.transform(test)\n",
        "# Prediction for the test set\n",
        "\n",
        "# Make predictions for the test set\n",
        "predictions = Best_Model.predict(test)\n",
        "\n",
        "# Convert labels to text\n",
        "label_encoder = le.inverse_transform(predictions)\n",
        "\n",
        "# Create a submission dataframe\n",
        "submission = pd.DataFrame({\n",
        "    'Activity_Name': label_encoder\n",
        "})\n",
        "\n",
        "# Save the submission dataframe\n",
        "#submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "# Evaluate the predictions on the test set\n",
        "print('Accuracy for the test set:', accuracy_score(y_true=submission['Activity_Name'], y_pred=label_encoder))\n",
        "print('Precision for the test set:', precision_score(y_true=submission['Activity_Name'], y_pred=label_encoder, average='weighted'))\n",
        "print('Recall for the test set:', recall_score(y_true=submission['Activity_Name'], y_pred=label_encoder, average='weighted'))\n",
        "print('F1-Score for the test set:', f1_score(y_true=submission['Activity_Name'], y_pred=label_encoder, average='weighted'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTNvqmEuZOFg"
      },
      "source": [
        "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
        "<font face=\"vazir\">ارزیابی</font>\n",
        "</h2>\n",
        "\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl;text-align: justify;line-height:200%;font-family:vazir;font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "معیاری که برای ارزیابی مدل شما استفاده خواهد شد <code>F1-score</code> نام دارد و آرگومان میانگین‌گیری آن معادل حالت وزن‌دار (<code dir=ltr>average='weighted'</code>) تنظیم خواهد شد. جهت مطالعه‌ی مستندات این کلاس می‌توانید به <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\" target=\"_blank\">این لینک</a> مراجعه فرمایید.\n",
        "</font>\n",
        "</p>\n",
        "\n",
        "\n",
        "$$F_1=\\frac{tp}{tp+\\frac{1}{2}(fp+fn)}$$\n",
        "\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl;text-align: justify;line-height:200%;font-family:vazir;font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "<span style=\"color:red\"><b>توجه:</b></span>\n",
        "جهت کسب امتیاز کامل نیاز است پاسخ شما حداقل مقدار(درصد) <code>96</code> را با توجه به این معیار کسب کند.\n",
        "<br>\n",
        "<span style=\"color:orange\"><b>نکته:</b></span>\n",
        "برای پاسخ‌هایی که عملکردی کمتر از این حد آستانه کسب کنند، امتیاز <code>0</code> منظور می‌شود و برای عملکردهایی بهتر از این حد آستانه،‌ به همان میزان، نمره‌ی اضافه برای این بخش در نظر گرفته خواهد شد.\n",
        "<br>\n",
        "<span style=\"color:orange\"><b>نکته:</b></span>\n",
        "از ذخیره بودن نت‌بوک خود در ارسال نهایی اطمینان حاصل کنید زیرا که نت‌بوک شما نیز مورد داوری دستی قرار خواهد گرفت و نمره‌ی نهایی شما از ترکیب نمره‌ی پیش‌بینی مدل و نمره‌ی داوری دستی (راه‌حل و تحلیل) محاسبه خواهد شد.\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwOhDrBxZOF0"
      },
      "source": [
        "<h2 align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
        "<font face=\"vazir\" color=\"#0099cc\">\n",
        "<b>سلول جواب‌ساز</b>\n",
        "</font>\n",
        "</h2>\n",
        "\n",
        "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
        "<font face=\"vazir\" size=3>\n",
        "    برای ساخته‌شدن فایل <code>result.zip</code> سلول زیر را اجرا کنید. توجه داشته باشید که پیش از اجرای سلول زیر تغییرات اعمال شده در نت‌بوک را ذخیره کرده باشید (<code>ctrl+s</code>) تا امکان بررسی کد شما وجود داشته باشد.\n",
        "</font>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUtaeU9AZOF1"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import joblib\n",
        "\n",
        "def compress(file_names):\n",
        "    print(\"File Paths:\")\n",
        "    print(file_names)\n",
        "    compression = zipfile.ZIP_DEFLATED\n",
        "    with zipfile.ZipFile(\"result.zip\", mode=\"w\") as zf:\n",
        "        for file_name in file_names:\n",
        "            zf.write('./' + file_name, file_name, compress_type=compression)\n",
        "\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "file_names = ['human_activity_classification.ipynb', 'submission.csv']\n",
        "compress(file_names)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "vscode": {
      "interpreter": {
        "hash": "44e7e1b8fa2096bd5707ed7fd18b1724a2db25f4c565a7673f8b6e7bfc49d25d"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}